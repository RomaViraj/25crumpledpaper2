{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ATV - Lesson 17 - Reference - v0.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RomaViraj/APT/blob/master/ATV_Lesson_17_confusion%20matrix_v0_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPTP12g0IwHF"
      },
      "source": [
        "# Lesson 17: Hunting Exoplanets In Space - Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4nx54DH_axk"
      },
      "source": [
        "**WARNING:** The reference notebook is meant **ONLY** for a teacher. Please **DO NOT** share it with any student. \n",
        "\n",
        "The contents of the reference notebook are meant only to prepare a teacher for a class. To conduct the class, use the class copy of the reference notebook. The link and the instructions for the same are provided in the **Notes To The Teacher** section.\n",
        "\n",
        "\n",
        "|Particulars|Description|\n",
        "|-|-|\n",
        "|**Topic**|Hunting Exoplanets In Space - Model Evaluation|\n",
        "|||\n",
        "|**Class Description**|In this class, a student will learn how to evaluate a classification model based on the precision, recall and f1-score values|\n",
        "|||\n",
        "|**Class**|C17|\n",
        "|||\n",
        "|**Class Time**|45 minutes|\n",
        "|||\n",
        "|**Goal**|Create a confusion matrix|\n",
        "||Compute the precision value|\n",
        "||Estimate the recall value|\n",
        "||Calculate the f1-score value|\n",
        "|||\n",
        "|**Teacher Resources**|Google Account|\n",
        "||Link to Lesson 17 Colab reference notebook|\n",
        "||Laptop with internet connectivity|\n",
        "||Earphones with mic|\n",
        "|||\n",
        "|**Student Resources**|Google Account|\n",
        "||Laptop with internet connectivity|\n",
        "||Earphones with mic|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y7VYng6_pgX"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2aywWdMAUry"
      },
      "source": [
        "### Class Structure\n",
        "\n",
        "A class is divided into three parts, as shown in the table below.\n",
        "\n",
        "|Parts|Duration|\n",
        "|-|-|\n",
        "|**Warm-Up**|5 minutes|\n",
        "|||\n",
        "|**Teacher-Student Activities**|35 minutes|\n",
        "|||\n",
        "|**Wrap-Up**|5 minutes|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAX0Fz3dATmH"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAufSWWDAdTQ"
      },
      "source": [
        "### Notes To The Teacher\n",
        "\n",
        "Before beginning the class:\n",
        "\n",
        "1. Open the **ATV - Lesson 17 - Class Copy - v0.2** file by clicking on the link provided in the **Activities** section under the title **Hunting Exoplanets In Space - Model Evaluation (Class Copy)**.  \n",
        "\n",
        "2. After opening the file mentioned in the first point, create its duplicate copy by following the steps described below:\n",
        "\n",
        "    - Click on the **File** menu. A new drop-down list will appear.\n",
        "\n",
        "      <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/0_file_menu.png' width=500>\n",
        "\n",
        "    - Click on the **Save a copy in Drive** option. A duplicate copy will get created. It will open up in the new tab on your web browser.\n",
        "\n",
        "      <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/1_create_colab_duplicate_copy.png' width=500>\n",
        "\n",
        "    - In the duplicate copy, click on the **Share** button on the top right corner of the notebook. A new dialog box will appear.\n",
        "\n",
        "      <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/2_share_button.png' width=500>\n",
        "\n",
        "    - Click on the tiny downward arrow next to **Anyone with the link can view** text. A drop-down list will appear.\n",
        "\n",
        "      <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/3_anyone_can_view.png' width=500>\n",
        "\n",
        "    - Click on the **More...** option. A new page on the dialog box will appear.\n",
        "\n",
        "      <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/4_more_option.png' width=500>\n",
        "\n",
        "    - Click on the circle next to **On - Anyone with the link** option. Now, go down and click on the tiny downward box next to **Can edit** text. A drop-down list will appear.\n",
        "\n",
        "      <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/5_anyone_with_the_link.png' width=500>\n",
        "\n",
        "    - Click on the **Can edit** option. Then click on the **Save** button. You will be directed back to the first page of the dialog box.\n",
        "\n",
        "      <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/6_can_edit.png' width=500>\n",
        "\n",
        "    - Make sure that under the **Link sharing on** section, **Anyone with the link can edit** option is selected. \n",
        "\n",
        "      <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/7_anyone_can_edit.png' width=500>\n",
        "\n",
        "    - Then click on the **Done** button.\n",
        "\n",
        "3. After creating the duplicate copy of the notebook, please rename it in the **YYYY-MM-DD_StudentName_Lesson17** format. \n",
        "\n",
        "4. Now, finish the **Warm-Up** section. Afterwards, proceed with the class using the duplicate copy of the notebook. You can share the link of the duplicate copy (named as **YYYY-MM-DD_StudentName_Lesson17**) with the student through the chat window.\n",
        "\n",
        "5. When a student executes the code for the first time in the duplicate copy that you shared with them, they may get the following warning:\n",
        "\n",
        "   ```\n",
        "    Warning: This notebook was not authored by Google. This notebook was \n",
        "    authored by xyz@gmail.com. It may request access to your data stored \n",
        "    with Google such as files, emails and contacts. Please review the source \n",
        "    code and contact the creator of this notebook at xyz@gmail.com with any \n",
        "    additional questions. \n",
        "\n",
        "                                                      Cancel. Run Anyway.\n",
        "  ```\n",
        "\n",
        "6. Ask the student to click on the `Run Anyway` button.\n",
        "\n",
        "7. Wherever you see the hat (**^**) sign on the heading of activity, give a hats-off to the student at the end of the activity.\n",
        "\n",
        "    - Single hat sign, i.e., **^** denotes give hats-off for concentration. You have to assess the concentration level of a student based on their attentiveness and understanding of the concept.\n",
        "\n",
        "    - Double hat signs, i.e., **^^** denotes give hats-off for creativity. It can be an alternative approach to writing a code for an activity or applying the logic in a totally different problem statement.\n",
        "\n",
        "    - Triple hat signs, i.e., **^^^** denotes give hats-off for persistence. It is the ability of a student to not give up on writing code and writing code with minimal teacher support.\n",
        "\n",
        "8. Every time you execute your code in the Google Colab notebook, please don't forget to save it by pressing the **Ctrl + S** keys (or **Command + S** keys if you are using a Mac). While saving the notebook, you or student may encounter the following error:\n",
        "\n",
        "   ```\n",
        "    Save failed\n",
        "    \n",
        "    The notebook has been changed outside of this session. Would you like to \n",
        "    overwrite existing changes?\n",
        "    \n",
        "                                                              CANCEL    YES\n",
        "   ```\n",
        "\n",
        "   Click on the `YES` button.\n",
        "\n",
        "9. Occasionally, you may encounter some error such as `NameError, ReferenceError, ImportError` or `ModuleNotFoundError` after executing the code in $k^{th}$ code cell (where $k > 0$). Most likely, due to poor internet speed, the Colab notebook might have lost the information that all the previous codes have been executed already. As a remedy, run codes in the code cells beginning from the first code cell till the $(k - 1)^{th}$ code cell. For e.g., if the code in the $5^{th}$ code cell fails to run because of one of the aforementioned errors, execute the codes in all the first four code cells again.\n",
        "\n",
        "10. For every **Teacher Action**, the teacher is supposed to share their screen with the student. Similarly, for every **Student Action**, the student is supposed to share their screen with the teacher.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eYTb9IbAZnL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1oPsYShAarL"
      },
      "source": [
        "### Warm-Up\n",
        "\n",
        "```\n",
        "TEACHER\n",
        "  Hi student_name! How are you doing?\n",
        "\n",
        "EXPECTED STUDENT RESPONSE\n",
        "  I am doing good, teacher. How about you?\n",
        "\n",
        "\n",
        "TEACHER\n",
        "  I am having a good time, thank you. So, how was your day? What did you do \n",
        "  today?\n",
        "\n",
        "EXPECTED STUDENT RESPONSE \n",
        "  I went to school. Had my lunch. Played a game and then did my homework \n",
        "  before this class.\n",
        "\n",
        "\n",
        "TEACHER\n",
        "  That's great. I am glad that you are having a good day. Now, let's do a \n",
        "  quick recap of our previous class. Can you recall the concepts you \n",
        "  learnt in the previous lesson?\n",
        "\n",
        "EXPECTED STUDENT RESPONSE\n",
        "  We learnt how to deploy the Random Forest Classifier prediction model \n",
        "  and how to separate the feature and target variables using the 'iloc[]'\n",
        "  function.\n",
        "\n",
        "\n",
        "TEACHER\n",
        "  Excellent! You recalled everything that you learnt in the last class. \n",
        "  Great job! Keep it up. \n",
        "  I have an exciting quiz question for you! Are you ready to answer this question?    \n",
        "  ```   \n",
        "  **Instructions for the Teacher:**\n",
        "  -  Please click on the \"Quiz Time\" button on the bottom right corner of your screen to start the In-Class Quiz.<img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/quiz-time.png' width=100>   \n",
        "  - A quiz will be visible to both you and the student. Encourage the student to answer the quiz question. \n",
        "  - The student may choose the wrong option, help the student to think correctly about the question and then answer again. \n",
        "  - After the student selects the correct option, the \"End Quiz\" button will start appearing on your screen.  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/end-quiz.png' width=100>  \n",
        "  - Click the \"End quiz\" to close the quiz pop-up and continue the class. \n",
        "  - Do not spend more than 2 minutes on this quiz.\n",
        "\n",
        "```\n",
        "TEACHER\n",
        "  Welcome to the Capstone Class. \n",
        "\n",
        "    Before we hop onto the Capstone challenge , let us complete today's task. \n",
        "    Our goal is to create a confusion matrix and calculate the F1-score value. \n",
        "  \n",
        "  So, are you excited for this class?\n",
        "\n",
        "EXPECTED STUDENT RESPONSE\n",
        "  Yes, teacher.\n",
        "\n",
        "\n",
        "TEACHER\n",
        "  All right. Let's get started. I'm sharing the link to the Colab notebook \n",
        "  for this class with you. Open it up.\n",
        "\n",
        "  Note:\n",
        "    - Share the duplicate copy of the notebook that you just created with \n",
        "      the student through the chat window.\n",
        "    \n",
        "EXPECTED STUDENT RESPONSE\n",
        "  The student opens the Colab notebook.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYw4DZm8AcYQ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdmZPtYSn7kA"
      },
      "source": [
        "### Teacher-Student Activities\n",
        "\n",
        "In the previous class, we deployed the `RandomForestClassifier` prediction model which classified the stars, in the test dataset, as `1` and `2`.\n",
        "\n",
        "The model turned out to be 99% accurate. However, in the dataset, `565` stars are classified as `1` and remaining `5` are classified as `2`. But the Random Forest Classifier model classified every star as `1`. Ideally, it should classify a few stars as `2` because the ultimate goal of the Kepler Space telescope was to find exoplanets in space.\n",
        "\n",
        "Hence, we need to ensure that for any kind of uneven distribution of data in the test dataset, our model should make accurate predictions. For this purpose, we need to evaluate the model that we deployed.\n",
        "\n",
        "Generally, a classification model (in this case, Random Forest Classification) is evaluated through a concept called **confusion matrix**.\n",
        "\n",
        "In this class, we will learn how to evaluate the performance of a classification-based machine learning model using a confusion matrix.\n",
        "\n",
        "\n",
        "Let's run all the codes in the code cells that we have already covered in the previous classes and begin this class from **Activity 1: The Confusion Matrix** section. You too run the code cells until the first activity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq9mAtEg9cpZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwzryU6Zie33"
      },
      "source": [
        "#### Loading The Datasets\n",
        "Create a Pandas DataFrame every time you start the Jupyter notebook.\n",
        "\n",
        "Dataset links (don't click on them):\n",
        "\n",
        "1. Train dataset\n",
        "\n",
        "  https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/kepler-exoplanets-dataset/exoTrain.csv\n",
        "\n",
        "2. Test dataset\n",
        "\n",
        "  https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/kepler-exoplanets-dataset/exoTest.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjScdqmQstFg"
      },
      "source": [
        "# Load the datasets.\n",
        "import pandas as pd\n",
        "\n",
        "exo_train_df = pd.read_csv('https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/kepler-exoplanets-dataset/exoTrain.csv')\n",
        "exo_test_df = pd.read_csv('https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/kepler-exoplanets-dataset/exoTest.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYateb4XmI6H"
      },
      "source": [
        "Check the number of rows and columns in the DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aGcwb3Ax10u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa720379-3473-4501-8f23-eba996b6e2ca"
      },
      "source": [
        "# Number of rows and columns in the DataFrames.\n",
        "print(exo_train_df.shape)\n",
        "exo_test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5087, 3198)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(570, 3198)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob_UHtcNaE-s"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcKiuR0gIvqi"
      },
      "source": [
        "#### The `value_counts()` Function\n",
        "\n",
        "To compute how many times a value occurs in a series, use the `value_counts()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG6oVSvRK6Jh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b1c6de55-6a82-4739-fbb7-3a6bf3e54418"
      },
      "source": [
        "# The number of times a value occurs in a Pandas series.\n",
        "exo_test_df['LABEL'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    565\n",
              "2      5\n",
              "Name: LABEL, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l7BTsS7LNLE"
      },
      "source": [
        "There are `565` stars which are classified as `1` and `5` stars classified as `2`. This means that only `5` stars have a planet.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmlkMPBed0wi"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3PeA6-AaO5J"
      },
      "source": [
        "#### Importing `RandomForestClassifier` Module\n",
        "We need to import a module called `RandomForestClassifier` from a package called `sklearn.ensemble`. The `sklearn` or **scikit-learn** is a collection of many machine learning modules. Almost every machine learning algorithm can be directly applied without a knowledge of math using the **scikit-learn** library. It is kind of a plug-and-play device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjyPky3Hh0fu"
      },
      "source": [
        "# Import the 'RandomForestClassifier' module from the 'sklearn.ensemble' library.\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8FljiKddvz9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP_x1sHBbWce"
      },
      "source": [
        "#### The Target & Feature Variables Separation\n",
        "\n",
        "The `RandomForestClassifier` module has a function called `fit()` which takes two inputs. The first input is the collection of feature variables. The second input is the target variable. Hence, we need to extract the target variable and the feature variables separately from the training dataset.\n",
        "\n",
        "Let's store the feature variables in the `x_train` variable and the target variable in the `y_train`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4xbNQzYj_CM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "90b2be9d-a591-4b87-d9a7-79ad56d7f47c"
      },
      "source": [
        "# Extract feature variables from the training dataset.\n",
        "x_train = exo_train_df.iloc[:, 1:]\n",
        "x_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FLUX.1</th>\n",
              "      <th>FLUX.2</th>\n",
              "      <th>FLUX.3</th>\n",
              "      <th>FLUX.4</th>\n",
              "      <th>FLUX.5</th>\n",
              "      <th>FLUX.6</th>\n",
              "      <th>FLUX.7</th>\n",
              "      <th>FLUX.8</th>\n",
              "      <th>FLUX.9</th>\n",
              "      <th>FLUX.10</th>\n",
              "      <th>FLUX.11</th>\n",
              "      <th>FLUX.12</th>\n",
              "      <th>FLUX.13</th>\n",
              "      <th>FLUX.14</th>\n",
              "      <th>FLUX.15</th>\n",
              "      <th>FLUX.16</th>\n",
              "      <th>FLUX.17</th>\n",
              "      <th>FLUX.18</th>\n",
              "      <th>FLUX.19</th>\n",
              "      <th>FLUX.20</th>\n",
              "      <th>FLUX.21</th>\n",
              "      <th>FLUX.22</th>\n",
              "      <th>FLUX.23</th>\n",
              "      <th>FLUX.24</th>\n",
              "      <th>FLUX.25</th>\n",
              "      <th>FLUX.26</th>\n",
              "      <th>FLUX.27</th>\n",
              "      <th>FLUX.28</th>\n",
              "      <th>FLUX.29</th>\n",
              "      <th>FLUX.30</th>\n",
              "      <th>FLUX.31</th>\n",
              "      <th>FLUX.32</th>\n",
              "      <th>FLUX.33</th>\n",
              "      <th>FLUX.34</th>\n",
              "      <th>FLUX.35</th>\n",
              "      <th>FLUX.36</th>\n",
              "      <th>FLUX.37</th>\n",
              "      <th>FLUX.38</th>\n",
              "      <th>FLUX.39</th>\n",
              "      <th>FLUX.40</th>\n",
              "      <th>...</th>\n",
              "      <th>FLUX.3158</th>\n",
              "      <th>FLUX.3159</th>\n",
              "      <th>FLUX.3160</th>\n",
              "      <th>FLUX.3161</th>\n",
              "      <th>FLUX.3162</th>\n",
              "      <th>FLUX.3163</th>\n",
              "      <th>FLUX.3164</th>\n",
              "      <th>FLUX.3165</th>\n",
              "      <th>FLUX.3166</th>\n",
              "      <th>FLUX.3167</th>\n",
              "      <th>FLUX.3168</th>\n",
              "      <th>FLUX.3169</th>\n",
              "      <th>FLUX.3170</th>\n",
              "      <th>FLUX.3171</th>\n",
              "      <th>FLUX.3172</th>\n",
              "      <th>FLUX.3173</th>\n",
              "      <th>FLUX.3174</th>\n",
              "      <th>FLUX.3175</th>\n",
              "      <th>FLUX.3176</th>\n",
              "      <th>FLUX.3177</th>\n",
              "      <th>FLUX.3178</th>\n",
              "      <th>FLUX.3179</th>\n",
              "      <th>FLUX.3180</th>\n",
              "      <th>FLUX.3181</th>\n",
              "      <th>FLUX.3182</th>\n",
              "      <th>FLUX.3183</th>\n",
              "      <th>FLUX.3184</th>\n",
              "      <th>FLUX.3185</th>\n",
              "      <th>FLUX.3186</th>\n",
              "      <th>FLUX.3187</th>\n",
              "      <th>FLUX.3188</th>\n",
              "      <th>FLUX.3189</th>\n",
              "      <th>FLUX.3190</th>\n",
              "      <th>FLUX.3191</th>\n",
              "      <th>FLUX.3192</th>\n",
              "      <th>FLUX.3193</th>\n",
              "      <th>FLUX.3194</th>\n",
              "      <th>FLUX.3195</th>\n",
              "      <th>FLUX.3196</th>\n",
              "      <th>FLUX.3197</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>93.85</td>\n",
              "      <td>83.81</td>\n",
              "      <td>20.10</td>\n",
              "      <td>-26.98</td>\n",
              "      <td>-39.56</td>\n",
              "      <td>-124.71</td>\n",
              "      <td>-135.18</td>\n",
              "      <td>-96.27</td>\n",
              "      <td>-79.89</td>\n",
              "      <td>-160.17</td>\n",
              "      <td>-207.47</td>\n",
              "      <td>-154.88</td>\n",
              "      <td>-173.71</td>\n",
              "      <td>-146.56</td>\n",
              "      <td>-120.26</td>\n",
              "      <td>-102.85</td>\n",
              "      <td>-98.71</td>\n",
              "      <td>-48.42</td>\n",
              "      <td>-86.57</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>-25.85</td>\n",
              "      <td>-67.39</td>\n",
              "      <td>-36.55</td>\n",
              "      <td>-87.01</td>\n",
              "      <td>-97.72</td>\n",
              "      <td>-131.59</td>\n",
              "      <td>-134.80</td>\n",
              "      <td>-186.97</td>\n",
              "      <td>-244.32</td>\n",
              "      <td>-225.76</td>\n",
              "      <td>-229.60</td>\n",
              "      <td>-253.48</td>\n",
              "      <td>-145.74</td>\n",
              "      <td>-145.74</td>\n",
              "      <td>30.47</td>\n",
              "      <td>-173.39</td>\n",
              "      <td>-187.56</td>\n",
              "      <td>-192.88</td>\n",
              "      <td>-182.76</td>\n",
              "      <td>-195.99</td>\n",
              "      <td>...</td>\n",
              "      <td>-167.69</td>\n",
              "      <td>-56.86</td>\n",
              "      <td>7.56</td>\n",
              "      <td>37.40</td>\n",
              "      <td>-81.13</td>\n",
              "      <td>-20.10</td>\n",
              "      <td>-30.34</td>\n",
              "      <td>-320.48</td>\n",
              "      <td>-320.48</td>\n",
              "      <td>-287.72</td>\n",
              "      <td>-351.25</td>\n",
              "      <td>-70.07</td>\n",
              "      <td>-194.34</td>\n",
              "      <td>-106.47</td>\n",
              "      <td>-14.80</td>\n",
              "      <td>63.13</td>\n",
              "      <td>130.03</td>\n",
              "      <td>76.43</td>\n",
              "      <td>131.90</td>\n",
              "      <td>-193.16</td>\n",
              "      <td>-193.16</td>\n",
              "      <td>-89.26</td>\n",
              "      <td>-17.56</td>\n",
              "      <td>-17.31</td>\n",
              "      <td>125.62</td>\n",
              "      <td>68.87</td>\n",
              "      <td>100.01</td>\n",
              "      <td>-9.60</td>\n",
              "      <td>-25.39</td>\n",
              "      <td>-16.51</td>\n",
              "      <td>-78.07</td>\n",
              "      <td>-102.15</td>\n",
              "      <td>-102.15</td>\n",
              "      <td>25.13</td>\n",
              "      <td>48.57</td>\n",
              "      <td>92.54</td>\n",
              "      <td>39.32</td>\n",
              "      <td>61.42</td>\n",
              "      <td>5.08</td>\n",
              "      <td>-39.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-38.88</td>\n",
              "      <td>-33.83</td>\n",
              "      <td>-58.54</td>\n",
              "      <td>-40.09</td>\n",
              "      <td>-79.31</td>\n",
              "      <td>-72.81</td>\n",
              "      <td>-86.55</td>\n",
              "      <td>-85.33</td>\n",
              "      <td>-83.97</td>\n",
              "      <td>-73.38</td>\n",
              "      <td>-86.51</td>\n",
              "      <td>-74.97</td>\n",
              "      <td>-73.15</td>\n",
              "      <td>-86.13</td>\n",
              "      <td>-76.57</td>\n",
              "      <td>-61.27</td>\n",
              "      <td>-37.23</td>\n",
              "      <td>-48.53</td>\n",
              "      <td>-30.96</td>\n",
              "      <td>-8.14</td>\n",
              "      <td>-5.54</td>\n",
              "      <td>15.79</td>\n",
              "      <td>45.71</td>\n",
              "      <td>10.61</td>\n",
              "      <td>40.66</td>\n",
              "      <td>16.70</td>\n",
              "      <td>15.18</td>\n",
              "      <td>11.98</td>\n",
              "      <td>-203.70</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>17.02</td>\n",
              "      <td>-8.50</td>\n",
              "      <td>-13.87</td>\n",
              "      <td>-29.10</td>\n",
              "      <td>-34.29</td>\n",
              "      <td>-24.68</td>\n",
              "      <td>...</td>\n",
              "      <td>-36.75</td>\n",
              "      <td>-15.49</td>\n",
              "      <td>-13.24</td>\n",
              "      <td>20.46</td>\n",
              "      <td>-1.47</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>27.80</td>\n",
              "      <td>-58.20</td>\n",
              "      <td>-58.20</td>\n",
              "      <td>-72.04</td>\n",
              "      <td>-58.01</td>\n",
              "      <td>-30.92</td>\n",
              "      <td>-13.42</td>\n",
              "      <td>-13.98</td>\n",
              "      <td>-5.43</td>\n",
              "      <td>8.71</td>\n",
              "      <td>1.80</td>\n",
              "      <td>36.59</td>\n",
              "      <td>-9.80</td>\n",
              "      <td>-19.53</td>\n",
              "      <td>-19.53</td>\n",
              "      <td>-24.32</td>\n",
              "      <td>-23.88</td>\n",
              "      <td>-33.07</td>\n",
              "      <td>-9.03</td>\n",
              "      <td>3.75</td>\n",
              "      <td>11.61</td>\n",
              "      <td>-12.66</td>\n",
              "      <td>-5.69</td>\n",
              "      <td>12.53</td>\n",
              "      <td>-3.28</td>\n",
              "      <td>-32.21</td>\n",
              "      <td>-32.21</td>\n",
              "      <td>-24.89</td>\n",
              "      <td>-4.86</td>\n",
              "      <td>0.76</td>\n",
              "      <td>-11.70</td>\n",
              "      <td>6.46</td>\n",
              "      <td>16.00</td>\n",
              "      <td>19.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>532.64</td>\n",
              "      <td>535.92</td>\n",
              "      <td>513.73</td>\n",
              "      <td>496.92</td>\n",
              "      <td>456.45</td>\n",
              "      <td>466.00</td>\n",
              "      <td>464.50</td>\n",
              "      <td>486.39</td>\n",
              "      <td>436.56</td>\n",
              "      <td>484.39</td>\n",
              "      <td>469.66</td>\n",
              "      <td>462.30</td>\n",
              "      <td>492.23</td>\n",
              "      <td>441.20</td>\n",
              "      <td>483.17</td>\n",
              "      <td>481.28</td>\n",
              "      <td>535.31</td>\n",
              "      <td>554.34</td>\n",
              "      <td>562.80</td>\n",
              "      <td>540.14</td>\n",
              "      <td>576.34</td>\n",
              "      <td>551.67</td>\n",
              "      <td>556.69</td>\n",
              "      <td>550.86</td>\n",
              "      <td>577.33</td>\n",
              "      <td>562.08</td>\n",
              "      <td>577.97</td>\n",
              "      <td>530.67</td>\n",
              "      <td>553.27</td>\n",
              "      <td>538.33</td>\n",
              "      <td>527.17</td>\n",
              "      <td>532.50</td>\n",
              "      <td>273.66</td>\n",
              "      <td>273.66</td>\n",
              "      <td>292.39</td>\n",
              "      <td>298.44</td>\n",
              "      <td>252.64</td>\n",
              "      <td>233.58</td>\n",
              "      <td>171.41</td>\n",
              "      <td>224.02</td>\n",
              "      <td>...</td>\n",
              "      <td>-51.09</td>\n",
              "      <td>-33.30</td>\n",
              "      <td>-61.53</td>\n",
              "      <td>-89.61</td>\n",
              "      <td>-69.17</td>\n",
              "      <td>-86.47</td>\n",
              "      <td>-140.91</td>\n",
              "      <td>-84.20</td>\n",
              "      <td>-84.20</td>\n",
              "      <td>-89.09</td>\n",
              "      <td>-55.44</td>\n",
              "      <td>-61.05</td>\n",
              "      <td>-29.17</td>\n",
              "      <td>-63.80</td>\n",
              "      <td>-57.61</td>\n",
              "      <td>2.70</td>\n",
              "      <td>-31.25</td>\n",
              "      <td>-47.09</td>\n",
              "      <td>-6.53</td>\n",
              "      <td>14.00</td>\n",
              "      <td>14.00</td>\n",
              "      <td>-25.05</td>\n",
              "      <td>-34.98</td>\n",
              "      <td>-32.08</td>\n",
              "      <td>-17.06</td>\n",
              "      <td>-27.77</td>\n",
              "      <td>7.86</td>\n",
              "      <td>-70.77</td>\n",
              "      <td>-64.44</td>\n",
              "      <td>-83.83</td>\n",
              "      <td>-71.69</td>\n",
              "      <td>13.31</td>\n",
              "      <td>13.31</td>\n",
              "      <td>-29.89</td>\n",
              "      <td>-20.88</td>\n",
              "      <td>5.06</td>\n",
              "      <td>-11.80</td>\n",
              "      <td>-28.91</td>\n",
              "      <td>-70.02</td>\n",
              "      <td>-96.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>326.52</td>\n",
              "      <td>347.39</td>\n",
              "      <td>302.35</td>\n",
              "      <td>298.13</td>\n",
              "      <td>317.74</td>\n",
              "      <td>312.70</td>\n",
              "      <td>322.33</td>\n",
              "      <td>311.31</td>\n",
              "      <td>312.42</td>\n",
              "      <td>323.33</td>\n",
              "      <td>311.14</td>\n",
              "      <td>326.19</td>\n",
              "      <td>313.11</td>\n",
              "      <td>313.89</td>\n",
              "      <td>317.96</td>\n",
              "      <td>330.92</td>\n",
              "      <td>341.10</td>\n",
              "      <td>360.58</td>\n",
              "      <td>370.29</td>\n",
              "      <td>369.71</td>\n",
              "      <td>339.00</td>\n",
              "      <td>336.24</td>\n",
              "      <td>319.31</td>\n",
              "      <td>321.56</td>\n",
              "      <td>308.02</td>\n",
              "      <td>296.82</td>\n",
              "      <td>279.34</td>\n",
              "      <td>275.78</td>\n",
              "      <td>289.67</td>\n",
              "      <td>281.33</td>\n",
              "      <td>285.37</td>\n",
              "      <td>281.87</td>\n",
              "      <td>88.75</td>\n",
              "      <td>88.75</td>\n",
              "      <td>67.71</td>\n",
              "      <td>74.46</td>\n",
              "      <td>69.34</td>\n",
              "      <td>76.51</td>\n",
              "      <td>80.26</td>\n",
              "      <td>70.31</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.75</td>\n",
              "      <td>14.29</td>\n",
              "      <td>-14.18</td>\n",
              "      <td>-25.14</td>\n",
              "      <td>-13.43</td>\n",
              "      <td>-14.74</td>\n",
              "      <td>2.24</td>\n",
              "      <td>-31.07</td>\n",
              "      <td>-31.07</td>\n",
              "      <td>-50.27</td>\n",
              "      <td>-39.22</td>\n",
              "      <td>-51.33</td>\n",
              "      <td>-18.53</td>\n",
              "      <td>-1.99</td>\n",
              "      <td>10.43</td>\n",
              "      <td>-1.97</td>\n",
              "      <td>-15.32</td>\n",
              "      <td>-23.38</td>\n",
              "      <td>-27.71</td>\n",
              "      <td>-36.12</td>\n",
              "      <td>-36.12</td>\n",
              "      <td>-15.65</td>\n",
              "      <td>6.63</td>\n",
              "      <td>10.66</td>\n",
              "      <td>-8.57</td>\n",
              "      <td>-8.29</td>\n",
              "      <td>-21.90</td>\n",
              "      <td>-25.80</td>\n",
              "      <td>-29.86</td>\n",
              "      <td>7.42</td>\n",
              "      <td>5.71</td>\n",
              "      <td>-3.73</td>\n",
              "      <td>-3.73</td>\n",
              "      <td>30.05</td>\n",
              "      <td>20.03</td>\n",
              "      <td>-12.67</td>\n",
              "      <td>-8.77</td>\n",
              "      <td>-17.31</td>\n",
              "      <td>-17.35</td>\n",
              "      <td>13.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1107.21</td>\n",
              "      <td>-1112.59</td>\n",
              "      <td>-1118.95</td>\n",
              "      <td>-1095.10</td>\n",
              "      <td>-1057.55</td>\n",
              "      <td>-1034.48</td>\n",
              "      <td>-998.34</td>\n",
              "      <td>-1022.71</td>\n",
              "      <td>-989.57</td>\n",
              "      <td>-970.88</td>\n",
              "      <td>-933.30</td>\n",
              "      <td>-889.49</td>\n",
              "      <td>-888.66</td>\n",
              "      <td>-853.95</td>\n",
              "      <td>-800.91</td>\n",
              "      <td>-754.48</td>\n",
              "      <td>-717.24</td>\n",
              "      <td>-649.34</td>\n",
              "      <td>-605.71</td>\n",
              "      <td>-575.62</td>\n",
              "      <td>-526.37</td>\n",
              "      <td>-490.12</td>\n",
              "      <td>-458.73</td>\n",
              "      <td>-447.76</td>\n",
              "      <td>-419.54</td>\n",
              "      <td>-410.76</td>\n",
              "      <td>-404.10</td>\n",
              "      <td>-425.38</td>\n",
              "      <td>-397.29</td>\n",
              "      <td>-412.73</td>\n",
              "      <td>-446.49</td>\n",
              "      <td>-413.46</td>\n",
              "      <td>-1006.21</td>\n",
              "      <td>-1006.21</td>\n",
              "      <td>-973.29</td>\n",
              "      <td>-986.01</td>\n",
              "      <td>-975.88</td>\n",
              "      <td>-982.20</td>\n",
              "      <td>-953.73</td>\n",
              "      <td>-964.35</td>\n",
              "      <td>...</td>\n",
              "      <td>-694.76</td>\n",
              "      <td>-705.01</td>\n",
              "      <td>-625.24</td>\n",
              "      <td>-604.16</td>\n",
              "      <td>-668.26</td>\n",
              "      <td>-742.18</td>\n",
              "      <td>-820.55</td>\n",
              "      <td>-874.76</td>\n",
              "      <td>-874.76</td>\n",
              "      <td>-853.68</td>\n",
              "      <td>-808.62</td>\n",
              "      <td>-777.88</td>\n",
              "      <td>-712.62</td>\n",
              "      <td>-694.01</td>\n",
              "      <td>-655.74</td>\n",
              "      <td>-599.74</td>\n",
              "      <td>-617.30</td>\n",
              "      <td>-602.98</td>\n",
              "      <td>-539.29</td>\n",
              "      <td>-672.71</td>\n",
              "      <td>-672.71</td>\n",
              "      <td>-594.49</td>\n",
              "      <td>-597.60</td>\n",
              "      <td>-560.77</td>\n",
              "      <td>-501.95</td>\n",
              "      <td>-461.62</td>\n",
              "      <td>-468.59</td>\n",
              "      <td>-513.24</td>\n",
              "      <td>-504.70</td>\n",
              "      <td>-521.95</td>\n",
              "      <td>-594.37</td>\n",
              "      <td>-401.66</td>\n",
              "      <td>-401.66</td>\n",
              "      <td>-357.24</td>\n",
              "      <td>-443.76</td>\n",
              "      <td>-438.54</td>\n",
              "      <td>-399.71</td>\n",
              "      <td>-384.65</td>\n",
              "      <td>-411.79</td>\n",
              "      <td>-510.54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3197 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    FLUX.1   FLUX.2   FLUX.3  ...  FLUX.3195  FLUX.3196  FLUX.3197\n",
              "0    93.85    83.81    20.10  ...      61.42       5.08     -39.54\n",
              "1   -38.88   -33.83   -58.54  ...       6.46      16.00      19.93\n",
              "2   532.64   535.92   513.73  ...     -28.91     -70.02     -96.67\n",
              "3   326.52   347.39   302.35  ...     -17.31     -17.35      13.98\n",
              "4 -1107.21 -1112.59 -1118.95  ...    -384.65    -411.79    -510.54\n",
              "\n",
              "[5 rows x 3197 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow3bOVajkEos",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b1a1da1a-6330-4049-e585-ab8f42dc149e"
      },
      "source": [
        "# Retrieve only the first column, i.e., the 'LABEL' column.\n",
        "y_train = exo_train_df.iloc[:, 0] \n",
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2\n",
              "1    2\n",
              "2    2\n",
              "3    2\n",
              "4    2\n",
              "Name: LABEL, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4c2YLzWdtiC"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSKFSFb5gZge"
      },
      "source": [
        "#### Fitting The Model\n",
        "Let's train the model using the `fit()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAU1jEBVkHG1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a47756b-3e4e-4d3f-a44a-33c0ec4e3b41"
      },
      "source": [
        "# Train the 'RandomForestClassifier' model using the 'fit()' function.\n",
        "rf_clf = RandomForestClassifier(n_jobs=-1, n_estimators=50)\n",
        "rf_clf.fit(x_train, y_train)\n",
        "\n",
        "rf_clf.score(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKq3HlbxhU0k"
      },
      "source": [
        "As you can see, we have built the Random Forest Classifier model with 50 decision trees. The fitting accuracy score of the model is 100%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV57P4UFh1rt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIi2Gikph5HQ"
      },
      "source": [
        "#### Target And Feature Variables From Test Dataset\n",
        "Now we need to make predictions on the test dataset. So, we just need to extract feature variables from the test dataset using the `iloc[]` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN1nsa2qpr80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "b96f0a00-bc16-4315-b937-cc488c00182d"
      },
      "source": [
        "# Extract the feature variables from the test dataset.\n",
        "x_test = exo_test_df.iloc[:, 1:]\n",
        "x_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FLUX.1</th>\n",
              "      <th>FLUX.2</th>\n",
              "      <th>FLUX.3</th>\n",
              "      <th>FLUX.4</th>\n",
              "      <th>FLUX.5</th>\n",
              "      <th>FLUX.6</th>\n",
              "      <th>FLUX.7</th>\n",
              "      <th>FLUX.8</th>\n",
              "      <th>FLUX.9</th>\n",
              "      <th>FLUX.10</th>\n",
              "      <th>FLUX.11</th>\n",
              "      <th>FLUX.12</th>\n",
              "      <th>FLUX.13</th>\n",
              "      <th>FLUX.14</th>\n",
              "      <th>FLUX.15</th>\n",
              "      <th>FLUX.16</th>\n",
              "      <th>FLUX.17</th>\n",
              "      <th>FLUX.18</th>\n",
              "      <th>FLUX.19</th>\n",
              "      <th>FLUX.20</th>\n",
              "      <th>FLUX.21</th>\n",
              "      <th>FLUX.22</th>\n",
              "      <th>FLUX.23</th>\n",
              "      <th>FLUX.24</th>\n",
              "      <th>FLUX.25</th>\n",
              "      <th>FLUX.26</th>\n",
              "      <th>FLUX.27</th>\n",
              "      <th>FLUX.28</th>\n",
              "      <th>FLUX.29</th>\n",
              "      <th>FLUX.30</th>\n",
              "      <th>FLUX.31</th>\n",
              "      <th>FLUX.32</th>\n",
              "      <th>FLUX.33</th>\n",
              "      <th>FLUX.34</th>\n",
              "      <th>FLUX.35</th>\n",
              "      <th>FLUX.36</th>\n",
              "      <th>FLUX.37</th>\n",
              "      <th>FLUX.38</th>\n",
              "      <th>FLUX.39</th>\n",
              "      <th>FLUX.40</th>\n",
              "      <th>...</th>\n",
              "      <th>FLUX.3158</th>\n",
              "      <th>FLUX.3159</th>\n",
              "      <th>FLUX.3160</th>\n",
              "      <th>FLUX.3161</th>\n",
              "      <th>FLUX.3162</th>\n",
              "      <th>FLUX.3163</th>\n",
              "      <th>FLUX.3164</th>\n",
              "      <th>FLUX.3165</th>\n",
              "      <th>FLUX.3166</th>\n",
              "      <th>FLUX.3167</th>\n",
              "      <th>FLUX.3168</th>\n",
              "      <th>FLUX.3169</th>\n",
              "      <th>FLUX.3170</th>\n",
              "      <th>FLUX.3171</th>\n",
              "      <th>FLUX.3172</th>\n",
              "      <th>FLUX.3173</th>\n",
              "      <th>FLUX.3174</th>\n",
              "      <th>FLUX.3175</th>\n",
              "      <th>FLUX.3176</th>\n",
              "      <th>FLUX.3177</th>\n",
              "      <th>FLUX.3178</th>\n",
              "      <th>FLUX.3179</th>\n",
              "      <th>FLUX.3180</th>\n",
              "      <th>FLUX.3181</th>\n",
              "      <th>FLUX.3182</th>\n",
              "      <th>FLUX.3183</th>\n",
              "      <th>FLUX.3184</th>\n",
              "      <th>FLUX.3185</th>\n",
              "      <th>FLUX.3186</th>\n",
              "      <th>FLUX.3187</th>\n",
              "      <th>FLUX.3188</th>\n",
              "      <th>FLUX.3189</th>\n",
              "      <th>FLUX.3190</th>\n",
              "      <th>FLUX.3191</th>\n",
              "      <th>FLUX.3192</th>\n",
              "      <th>FLUX.3193</th>\n",
              "      <th>FLUX.3194</th>\n",
              "      <th>FLUX.3195</th>\n",
              "      <th>FLUX.3196</th>\n",
              "      <th>FLUX.3197</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119.88</td>\n",
              "      <td>100.21</td>\n",
              "      <td>86.46</td>\n",
              "      <td>48.68</td>\n",
              "      <td>46.12</td>\n",
              "      <td>39.39</td>\n",
              "      <td>18.57</td>\n",
              "      <td>6.98</td>\n",
              "      <td>6.63</td>\n",
              "      <td>-21.97</td>\n",
              "      <td>-23.17</td>\n",
              "      <td>-29.26</td>\n",
              "      <td>-33.99</td>\n",
              "      <td>-6.25</td>\n",
              "      <td>-28.12</td>\n",
              "      <td>-27.24</td>\n",
              "      <td>-32.28</td>\n",
              "      <td>-12.29</td>\n",
              "      <td>-16.57</td>\n",
              "      <td>-23.86</td>\n",
              "      <td>-5.69</td>\n",
              "      <td>9.24</td>\n",
              "      <td>35.52</td>\n",
              "      <td>81.20</td>\n",
              "      <td>116.49</td>\n",
              "      <td>133.99</td>\n",
              "      <td>148.97</td>\n",
              "      <td>174.15</td>\n",
              "      <td>187.77</td>\n",
              "      <td>215.30</td>\n",
              "      <td>246.80</td>\n",
              "      <td>-56.68</td>\n",
              "      <td>-56.68</td>\n",
              "      <td>-56.68</td>\n",
              "      <td>-52.05</td>\n",
              "      <td>-31.52</td>\n",
              "      <td>-31.15</td>\n",
              "      <td>-48.53</td>\n",
              "      <td>-38.93</td>\n",
              "      <td>-26.06</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.55</td>\n",
              "      <td>12.26</td>\n",
              "      <td>-7.06</td>\n",
              "      <td>-23.53</td>\n",
              "      <td>2.54</td>\n",
              "      <td>30.21</td>\n",
              "      <td>38.87</td>\n",
              "      <td>-22.86</td>\n",
              "      <td>-22.86</td>\n",
              "      <td>-4.37</td>\n",
              "      <td>2.27</td>\n",
              "      <td>-16.27</td>\n",
              "      <td>-30.84</td>\n",
              "      <td>-7.21</td>\n",
              "      <td>-4.27</td>\n",
              "      <td>13.60</td>\n",
              "      <td>15.62</td>\n",
              "      <td>31.96</td>\n",
              "      <td>49.89</td>\n",
              "      <td>86.93</td>\n",
              "      <td>86.93</td>\n",
              "      <td>42.99</td>\n",
              "      <td>48.76</td>\n",
              "      <td>22.82</td>\n",
              "      <td>32.79</td>\n",
              "      <td>30.76</td>\n",
              "      <td>14.55</td>\n",
              "      <td>10.92</td>\n",
              "      <td>22.68</td>\n",
              "      <td>5.91</td>\n",
              "      <td>14.52</td>\n",
              "      <td>19.29</td>\n",
              "      <td>14.44</td>\n",
              "      <td>-1.62</td>\n",
              "      <td>13.33</td>\n",
              "      <td>45.50</td>\n",
              "      <td>31.93</td>\n",
              "      <td>35.78</td>\n",
              "      <td>269.43</td>\n",
              "      <td>57.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5736.59</td>\n",
              "      <td>5699.98</td>\n",
              "      <td>5717.16</td>\n",
              "      <td>5692.73</td>\n",
              "      <td>5663.83</td>\n",
              "      <td>5631.16</td>\n",
              "      <td>5626.39</td>\n",
              "      <td>5569.47</td>\n",
              "      <td>5550.44</td>\n",
              "      <td>5458.80</td>\n",
              "      <td>5329.39</td>\n",
              "      <td>5191.38</td>\n",
              "      <td>5031.39</td>\n",
              "      <td>4769.89</td>\n",
              "      <td>4419.66</td>\n",
              "      <td>4218.92</td>\n",
              "      <td>3924.73</td>\n",
              "      <td>3605.30</td>\n",
              "      <td>3326.55</td>\n",
              "      <td>3021.20</td>\n",
              "      <td>2800.61</td>\n",
              "      <td>2474.48</td>\n",
              "      <td>2258.33</td>\n",
              "      <td>1951.69</td>\n",
              "      <td>1749.86</td>\n",
              "      <td>1585.38</td>\n",
              "      <td>1575.48</td>\n",
              "      <td>1568.41</td>\n",
              "      <td>1661.08</td>\n",
              "      <td>1977.33</td>\n",
              "      <td>2425.62</td>\n",
              "      <td>2889.61</td>\n",
              "      <td>3847.64</td>\n",
              "      <td>3847.64</td>\n",
              "      <td>3741.20</td>\n",
              "      <td>3453.47</td>\n",
              "      <td>3202.61</td>\n",
              "      <td>2923.73</td>\n",
              "      <td>2694.84</td>\n",
              "      <td>2474.22</td>\n",
              "      <td>...</td>\n",
              "      <td>-3470.75</td>\n",
              "      <td>-4510.72</td>\n",
              "      <td>-5013.41</td>\n",
              "      <td>-3636.05</td>\n",
              "      <td>-2324.27</td>\n",
              "      <td>-2688.55</td>\n",
              "      <td>-2813.66</td>\n",
              "      <td>-586.22</td>\n",
              "      <td>-586.22</td>\n",
              "      <td>-756.80</td>\n",
              "      <td>-1090.23</td>\n",
              "      <td>-1388.61</td>\n",
              "      <td>-1745.36</td>\n",
              "      <td>-2015.28</td>\n",
              "      <td>-2359.06</td>\n",
              "      <td>-2516.66</td>\n",
              "      <td>-2699.31</td>\n",
              "      <td>-2777.55</td>\n",
              "      <td>-2732.97</td>\n",
              "      <td>1167.39</td>\n",
              "      <td>1167.39</td>\n",
              "      <td>1368.89</td>\n",
              "      <td>1434.80</td>\n",
              "      <td>1360.75</td>\n",
              "      <td>1148.44</td>\n",
              "      <td>1117.67</td>\n",
              "      <td>714.86</td>\n",
              "      <td>419.02</td>\n",
              "      <td>57.06</td>\n",
              "      <td>-175.66</td>\n",
              "      <td>-581.91</td>\n",
              "      <td>-984.09</td>\n",
              "      <td>-1230.89</td>\n",
              "      <td>-1600.45</td>\n",
              "      <td>-1824.53</td>\n",
              "      <td>-2061.17</td>\n",
              "      <td>-2265.98</td>\n",
              "      <td>-2366.19</td>\n",
              "      <td>-2294.86</td>\n",
              "      <td>-2034.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>844.48</td>\n",
              "      <td>817.49</td>\n",
              "      <td>770.07</td>\n",
              "      <td>675.01</td>\n",
              "      <td>605.52</td>\n",
              "      <td>499.45</td>\n",
              "      <td>440.77</td>\n",
              "      <td>362.95</td>\n",
              "      <td>207.27</td>\n",
              "      <td>150.46</td>\n",
              "      <td>85.49</td>\n",
              "      <td>-20.12</td>\n",
              "      <td>-35.88</td>\n",
              "      <td>-65.59</td>\n",
              "      <td>-15.12</td>\n",
              "      <td>16.60</td>\n",
              "      <td>-25.70</td>\n",
              "      <td>61.88</td>\n",
              "      <td>53.18</td>\n",
              "      <td>64.32</td>\n",
              "      <td>72.38</td>\n",
              "      <td>100.35</td>\n",
              "      <td>67.26</td>\n",
              "      <td>14.71</td>\n",
              "      <td>-16.41</td>\n",
              "      <td>-147.46</td>\n",
              "      <td>-231.27</td>\n",
              "      <td>-320.29</td>\n",
              "      <td>-407.82</td>\n",
              "      <td>-450.48</td>\n",
              "      <td>-146.99</td>\n",
              "      <td>-146.99</td>\n",
              "      <td>-146.99</td>\n",
              "      <td>-146.99</td>\n",
              "      <td>-166.30</td>\n",
              "      <td>-139.90</td>\n",
              "      <td>-96.41</td>\n",
              "      <td>-23.49</td>\n",
              "      <td>13.59</td>\n",
              "      <td>67.59</td>\n",
              "      <td>...</td>\n",
              "      <td>-35.24</td>\n",
              "      <td>-70.13</td>\n",
              "      <td>-35.30</td>\n",
              "      <td>-56.48</td>\n",
              "      <td>-74.60</td>\n",
              "      <td>-115.18</td>\n",
              "      <td>-8.91</td>\n",
              "      <td>-37.59</td>\n",
              "      <td>-37.59</td>\n",
              "      <td>-37.43</td>\n",
              "      <td>-104.23</td>\n",
              "      <td>-101.45</td>\n",
              "      <td>-107.35</td>\n",
              "      <td>-109.82</td>\n",
              "      <td>-126.27</td>\n",
              "      <td>-170.32</td>\n",
              "      <td>-117.85</td>\n",
              "      <td>-32.30</td>\n",
              "      <td>-70.18</td>\n",
              "      <td>314.29</td>\n",
              "      <td>314.29</td>\n",
              "      <td>314.29</td>\n",
              "      <td>149.71</td>\n",
              "      <td>54.60</td>\n",
              "      <td>12.60</td>\n",
              "      <td>-133.68</td>\n",
              "      <td>-78.16</td>\n",
              "      <td>-52.30</td>\n",
              "      <td>-8.55</td>\n",
              "      <td>-19.73</td>\n",
              "      <td>17.82</td>\n",
              "      <td>-51.66</td>\n",
              "      <td>-48.29</td>\n",
              "      <td>-59.99</td>\n",
              "      <td>-82.10</td>\n",
              "      <td>-174.54</td>\n",
              "      <td>-95.23</td>\n",
              "      <td>-162.68</td>\n",
              "      <td>-36.79</td>\n",
              "      <td>30.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-826.00</td>\n",
              "      <td>-827.31</td>\n",
              "      <td>-846.12</td>\n",
              "      <td>-836.03</td>\n",
              "      <td>-745.50</td>\n",
              "      <td>-784.69</td>\n",
              "      <td>-791.22</td>\n",
              "      <td>-746.50</td>\n",
              "      <td>-709.53</td>\n",
              "      <td>-679.56</td>\n",
              "      <td>-706.03</td>\n",
              "      <td>-720.56</td>\n",
              "      <td>-631.12</td>\n",
              "      <td>-659.16</td>\n",
              "      <td>-672.03</td>\n",
              "      <td>-665.06</td>\n",
              "      <td>-667.94</td>\n",
              "      <td>-660.84</td>\n",
              "      <td>-672.75</td>\n",
              "      <td>-644.91</td>\n",
              "      <td>-680.53</td>\n",
              "      <td>-620.50</td>\n",
              "      <td>-570.34</td>\n",
              "      <td>-530.00</td>\n",
              "      <td>-537.88</td>\n",
              "      <td>-578.38</td>\n",
              "      <td>-532.34</td>\n",
              "      <td>-532.38</td>\n",
              "      <td>-491.03</td>\n",
              "      <td>-485.03</td>\n",
              "      <td>-427.19</td>\n",
              "      <td>-380.84</td>\n",
              "      <td>-329.50</td>\n",
              "      <td>-286.91</td>\n",
              "      <td>-283.81</td>\n",
              "      <td>-298.19</td>\n",
              "      <td>-271.03</td>\n",
              "      <td>-268.50</td>\n",
              "      <td>-209.56</td>\n",
              "      <td>-180.44</td>\n",
              "      <td>...</td>\n",
              "      <td>16.50</td>\n",
              "      <td>-1286.59</td>\n",
              "      <td>-1286.59</td>\n",
              "      <td>-1286.59</td>\n",
              "      <td>-1286.59</td>\n",
              "      <td>-1286.59</td>\n",
              "      <td>-1286.59</td>\n",
              "      <td>-1286.59</td>\n",
              "      <td>-1286.59</td>\n",
              "      <td>-14.94</td>\n",
              "      <td>64.09</td>\n",
              "      <td>8.38</td>\n",
              "      <td>45.31</td>\n",
              "      <td>100.72</td>\n",
              "      <td>91.53</td>\n",
              "      <td>46.69</td>\n",
              "      <td>20.34</td>\n",
              "      <td>30.94</td>\n",
              "      <td>-36.81</td>\n",
              "      <td>-33.28</td>\n",
              "      <td>-69.62</td>\n",
              "      <td>-208.00</td>\n",
              "      <td>-280.28</td>\n",
              "      <td>-340.41</td>\n",
              "      <td>-337.41</td>\n",
              "      <td>-268.03</td>\n",
              "      <td>-245.00</td>\n",
              "      <td>-230.62</td>\n",
              "      <td>-129.59</td>\n",
              "      <td>-35.47</td>\n",
              "      <td>122.34</td>\n",
              "      <td>93.03</td>\n",
              "      <td>93.03</td>\n",
              "      <td>68.81</td>\n",
              "      <td>9.81</td>\n",
              "      <td>20.75</td>\n",
              "      <td>20.25</td>\n",
              "      <td>-120.81</td>\n",
              "      <td>-257.56</td>\n",
              "      <td>-215.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-39.57</td>\n",
              "      <td>-15.88</td>\n",
              "      <td>-9.16</td>\n",
              "      <td>-6.37</td>\n",
              "      <td>-16.13</td>\n",
              "      <td>-24.05</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-45.20</td>\n",
              "      <td>-5.04</td>\n",
              "      <td>14.62</td>\n",
              "      <td>-19.52</td>\n",
              "      <td>-11.43</td>\n",
              "      <td>-49.80</td>\n",
              "      <td>25.84</td>\n",
              "      <td>11.62</td>\n",
              "      <td>3.18</td>\n",
              "      <td>-9.59</td>\n",
              "      <td>14.49</td>\n",
              "      <td>8.82</td>\n",
              "      <td>32.32</td>\n",
              "      <td>-28.90</td>\n",
              "      <td>-28.90</td>\n",
              "      <td>-14.09</td>\n",
              "      <td>-30.87</td>\n",
              "      <td>-18.99</td>\n",
              "      <td>-38.60</td>\n",
              "      <td>-27.79</td>\n",
              "      <td>9.65</td>\n",
              "      <td>29.60</td>\n",
              "      <td>7.88</td>\n",
              "      <td>42.87</td>\n",
              "      <td>27.59</td>\n",
              "      <td>27.05</td>\n",
              "      <td>20.26</td>\n",
              "      <td>29.48</td>\n",
              "      <td>9.71</td>\n",
              "      <td>22.84</td>\n",
              "      <td>25.99</td>\n",
              "      <td>-667.55</td>\n",
              "      <td>-1336.24</td>\n",
              "      <td>...</td>\n",
              "      <td>-122.12</td>\n",
              "      <td>-32.01</td>\n",
              "      <td>-47.15</td>\n",
              "      <td>-56.45</td>\n",
              "      <td>-41.71</td>\n",
              "      <td>-34.13</td>\n",
              "      <td>-43.12</td>\n",
              "      <td>-53.63</td>\n",
              "      <td>-53.63</td>\n",
              "      <td>-53.63</td>\n",
              "      <td>-24.29</td>\n",
              "      <td>22.29</td>\n",
              "      <td>25.18</td>\n",
              "      <td>1.84</td>\n",
              "      <td>-22.29</td>\n",
              "      <td>-26.43</td>\n",
              "      <td>-12.12</td>\n",
              "      <td>-33.05</td>\n",
              "      <td>-21.66</td>\n",
              "      <td>-228.32</td>\n",
              "      <td>-228.32</td>\n",
              "      <td>-228.32</td>\n",
              "      <td>-187.35</td>\n",
              "      <td>-166.23</td>\n",
              "      <td>-115.54</td>\n",
              "      <td>-50.18</td>\n",
              "      <td>-37.96</td>\n",
              "      <td>-22.37</td>\n",
              "      <td>-4.74</td>\n",
              "      <td>-35.82</td>\n",
              "      <td>-37.87</td>\n",
              "      <td>-61.85</td>\n",
              "      <td>-27.15</td>\n",
              "      <td>-21.18</td>\n",
              "      <td>-33.76</td>\n",
              "      <td>-85.34</td>\n",
              "      <td>-81.46</td>\n",
              "      <td>-61.98</td>\n",
              "      <td>-69.34</td>\n",
              "      <td>-17.84</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3197 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    FLUX.1   FLUX.2   FLUX.3  ...  FLUX.3195  FLUX.3196  FLUX.3197\n",
              "0   119.88   100.21    86.46  ...      35.78     269.43      57.72\n",
              "1  5736.59  5699.98  5717.16  ...   -2366.19   -2294.86   -2034.72\n",
              "2   844.48   817.49   770.07  ...    -162.68     -36.79      30.63\n",
              "3  -826.00  -827.31  -846.12  ...    -120.81    -257.56    -215.41\n",
              "4   -39.57   -15.88    -9.16  ...     -61.98     -69.34     -17.84\n",
              "\n",
              "[5 rows x 3197 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsZe8fyeiXBG"
      },
      "source": [
        "Let's also extract the target variable from the test dataset so that we can compare the actual target values with the predicted values later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVMq86Y5p5ol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7f9e34e7-c6f0-465f-c095-8283f8170f0c"
      },
      "source": [
        "# Extract the target variable from the test dataset.\n",
        "y_test = exo_test_df.iloc[:, 0]\n",
        "y_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2\n",
              "1    2\n",
              "2    2\n",
              "3    2\n",
              "4    2\n",
              "Name: LABEL, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f3OVTo4ioQk"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz8BPprpipOq"
      },
      "source": [
        "#### The `predict()` Function\n",
        "Now, let's make predictions on the test dataset by calling the `predict()` function with the features variables of the test dataset as an input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF_lb5Fcp8zd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "209585d9-4c86-4c1a-98a6-3af089de2581"
      },
      "source": [
        "# Make predictions using the 'predict()' function.\n",
        "y_predicted = rf_clf.predict(x_test)\n",
        "y_predicted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhdBmNx8jWQv"
      },
      "source": [
        "The actual target values are stored in a Pandas series. So, for the sake of consistency, let's convert the NumPy array of the predicted values into a Pandas series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF3skQa0qBeO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bd704542-40b2-43ee-f273-c83681d5877d"
      },
      "source": [
        "# Convert the NumPy array of predicted values into a Pandas series.\n",
        "y_predicted = pd.Series(y_predicted)\n",
        "y_predicted.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQwrexkrjrdE"
      },
      "source": [
        "Now, let's count the number of stars classified as `1` and `2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk7UnroAqTUT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa52bc90-2145-499f-fd12-9a64ea5bdf0e"
      },
      "source": [
        "# Using the 'value_counts()' function, count the number of times 1 and 2 occur in the predicted values.\n",
        "y_predicted.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    570\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3WclLnZkFfz"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EunyjTuSOb1"
      },
      "source": [
        "#### Activity 1: The Confusion Matrix\n",
        "Let's quickly first create a confusion matrix and then will try to understand it.\n",
        "\n",
        "To create a confusion matrix, first import `confusion_matrix` module from the `sklearn.metrics` library. This library contains all the parameters to evaluate a machine learning model. In addition to the `confusion_matrix` module, let's also import the `classification_report` module. We will use them later to evaluate our module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bzvMefbUQ7A"
      },
      "source": [
        "# Teacher Action: Import the 'confusion_matrix' and 'classification_report' functions from the 'sklearn.metrics' module.\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjnA_MB4UgVQ"
      },
      "source": [
        "Now, create the confusion matrix using the `confusion_matrix()` function. It requires two inputs. The first input is actual target values (`y_test`) and the second input is predicted target values (`y_predicted`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z33zddaxqDnO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8aebb48b-521d-4b3d-e437-e3ea23ab8371"
      },
      "source": [
        "# Teacher Action: Create a confusion matrix using the 'y_test' and 'y_predicted' values.\n",
        "confusion_matrix(y_test, y_predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[565,   0],\n",
              "       [  5,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy1hFeqqTSYE"
      },
      "source": [
        "Now that we have got our confusion matrix, let's try to understand this concept.\n",
        "\n",
        "**Confusion Matrix:**\n",
        "---\n",
        "\n",
        "It is way of evaluating the performance of your machine learning algorithm.\n",
        "\n",
        "**For Example:**\n",
        "\n",
        "Suppose that you attempted an online exam in which you already know that out of 100 questions, you have given 75 correct answers and 25 incorrect answers.\n",
        "\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/WHJ-BOY-TYPING-APT-C17.gif\" height=400/>\n",
        "\n",
        "\n",
        "However, the exam software did not assessed the answers correctly and marked many correct answers as incorrect and incorrect answers as correct. Let us evaluate the performance of this software using confusion matrix.\n",
        "\n",
        "- There are two possible classes:\n",
        "  1. Class `correct`.\n",
        "  2. Class `incorrect`.\n",
        "\n",
        "We need to find out how many correct answers were accurately assessed or predicted by the software. \n",
        "\n",
        "Thus, \n",
        "- positive outcome $\\Rightarrow$ `correct` answer.\n",
        "- negative outcome $\\Rightarrow$ `incorrect` answer.\n",
        "\n",
        "In technical terms, the desired outcome is called a **positive outcome**. \n",
        "\n",
        "\n",
        "Now, consider the following table and a `2 X 2` matrix known as **confusion matrix**. This table shows the actual and predicted values for the first 4 questions.\n",
        "\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/table2.PNG\"/>\n",
        "\n",
        "```\n",
        "TEACHER\n",
        "   here the first row indicates that the answer to the first question was \n",
        "   actually incorrect and the system also marked it incorrect. Thus, the \n",
        "   first question was accurately assessed by the software.\n",
        "\n",
        "   Similarly, the third row indicates that the answer to the third question was \n",
        "   actually correct, however the system marked it as incorrect. Thus the \n",
        "   software performed incorrect assessment of the third question\n",
        "```\n",
        "\n",
        "Now let us have a look at each cell of the confusion matrix.\n",
        "\n",
        "1. The first row first column value indicates those `incorrect` answers which were <b><font color=green>accurately</font></b> assessed or predicted as `incorrect` by the software.\n",
        "Such values are called as **True Negative (TN)**.\n",
        "\n",
        "\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/True_negative.png\"/>\n",
        "\n",
        "2. The second  row second column value  indicates those `correct` answers which were <b><font color=green>accurately</font></b> assessed or predicted as `correct` by the software.\n",
        "Such values are called as **True Positive (TP)**.\n",
        "\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/true_positives.png\"/>\n",
        "\n",
        "3. The second  row first column value  indicates those `correct`  answers which were <b><font color=red>inaccurately</font></b>  assessed or predicted as `incorrect` by the software.\n",
        "Such values are called as **False Negative (FN)**.\n",
        "\n",
        "\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/fn.png\"/>\n",
        "\n",
        "4. The first  row second column value  indicates those `incorrect`  answers which were <b><font color=red>inaccurately</font></b>  assessed or predicted as `correct` by the software.\n",
        "Such values are called **False Positive (FP)**.\n",
        "\n",
        "\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/FP.png\"/>\n",
        "\n",
        "\n",
        "The resultant confusion matrix obtained after evaluating values for all the 100 questions are as follows:\n",
        "\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/whj-negative-positive-apt-c17-01.png\" height=300/>\n",
        "\n",
        "\n",
        "- Values that are accurately predicted or assessed by the model are labelled **True (T)**. Thus, the number of answers which were <b><font color=green>accurately</font></b> predicted by the software = `85`\n",
        "\n",
        "\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/whj-85-ans-apt-c17.gif\" height=450/>\n",
        "\n",
        "- Values that are inaccurately predicted or assessed by the model are labelled **False (F)**. Thus, the number of answers which were <b><font color=red>inaccurately</font></b> predicted by the software = `15`\n",
        "\n",
        "\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/whj-15-answers-apt-c17.gif\" height=450/>\n",
        "\n",
        "Thus the confusion matrix compares the actual values with the predicted values and thus it is very useful in evaluating the performance of your machine learning model.\n",
        "\n",
        "---\n",
        "\n",
        "Let us apply the concept of confusion matrix for our dataset.\n",
        "\n",
        "There are two possible classes:\n",
        "1. The class `1` values are stars **NOT** having a planet.\n",
        "2. The class `2` values are stars having a planet.\n",
        "\n",
        " So, after you deploy the classification model, there are 4 possible outcomes. They are:\n",
        "\n",
        "1. Class `1` values predicted as class `1`. \n",
        "\n",
        "2. Class `1` values predicted as class `2`.\n",
        "\n",
        "3. Class `2` values predicted as class `1`.\n",
        "\n",
        "4. Class `2` values predicted as class `2`.\n",
        "\n",
        "These 4 possibilities can be reported in a confusion matrix. \n",
        "\n",
        "||Predicted Class `1` (`y_predicted`)|Predicted Class `2` (`y_predicted`)|\n",
        "|-|-|-|\n",
        "|Actual Class `1` (`y_test`)|||\n",
        "|Actual Class `2` (`y_test`)|||\n",
        "\n",
        "where\n",
        "\n",
        "- `y_test` contains the actual class `1` and class `2` values\n",
        "\n",
        "- `y_predicted` contains the predicted class `1` and class `2` values\n",
        "\n",
        "In this table,\n",
        "\n",
        "- the values **predicted as class `1` and actually belonging to class `1`** are reported in the first row and first column.\n",
        "\n",
        "||Predicted Class `1` (`y_predicted`)|Predicted Class `2` (`y_predicted`)|\n",
        "|-|-|-|\n",
        "|Actual Class `1` (`y_test`)|565||\n",
        "|Actual Class `2` (`y_test`)|||\n",
        "\n",
        "- the values **predicted as class `1` but actually belonging to class `2`** are reported in the second row and first column. \n",
        "\n",
        "||Predicted Class `1` (`y_predicted`)|Predicted Class `2` (`y_predicted`)|\n",
        "|-|-|-|\n",
        "|Actual Class `1` (`y_test`)|565||\n",
        "|Actual Class `2` (`y_test`)|5||\n",
        "\n",
        "- the values **predicted as class `2` and actually belonging to class `2`** are reported in the second row and second column.\n",
        "\n",
        "||Predicted Class `1` (`y_predicted`)|Predicted Class `2` (`y_predicted`)|\n",
        "|-|-|-|\n",
        "|Actual Class `1` (`y_test`)|565||\n",
        "|Actual Class `2` (`y_test`)|5|0|\n",
        "\n",
        "- the values **predicted as class `2` but actually belonging to class `1`** are reported in the first row and second column.\n",
        "\n",
        "||Predicted Class `1` (`y_predicted`)|Predicted Class `2` (`y_predicted`)|\n",
        "|-|-|-|\n",
        "|Actual Class `1` (`y_test`)|565|0|\n",
        "|Actual Class `2` (`y_test`)|5|0|\n",
        "\n",
        "In this case, the class `1` values refer to the stars not having a planet whereas class `2` values refer to the stars having a planet. \n",
        "\n",
        "**Positive Outcome**\n",
        "\n",
        "Detecting a star having a planet is the desired outcome (positive outcome). \n",
        "Thus, \n",
        "- positive outcome $\\Rightarrow$ class `2`.\n",
        "\n",
        "- negative outcome $\\Rightarrow$ class `1`.\n",
        "\n",
        "So, here the positive outcome is the prediction of the stars having a planet, i.e., prediction of the class `2` values. Likewise, finding a star which does not have any planet is a *negative outcome*. So, here the negative outcome is the prediction of the class `1` values. \n",
        "\n",
        "Observe the output of `confusion_matrix(y_test, y_predicted)` function.\n",
        "\n",
        "```\n",
        "array([[565,   0],\n",
        "       [  5,   0]])\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- `565` values are **True Negative (TN)** values because they are **truly** predicted as class `1` values.\n",
        "\n",
        "||Predicted Class `1` (`y_predicted`)|Predicted Class `2` (`y_predicted`)|\n",
        "|-|-|-|\n",
        "|Actual Class `1` (`y_test`)|565 (TN)||\n",
        "|Actual Class `2` (`y_test`)|||\n",
        "\n",
        "\n",
        "- `5` values are **False Negative (FN)** values because they are **falsely** predicted as class `1` values. They should have been predicted as class `2` values.\n",
        "\n",
        "||Predicted Class `1` (`y_predicted`)|Predicted Class `2` (`y_predicted`)|\n",
        "|-|-|-|\n",
        "|Actual Class `1` (`y_test`)|565 (TN)||\n",
        "|Actual Class `2` (`y_test`)|5 (FN)||\n",
        "\n",
        "\n",
        "- `0` values are **True Positive (TP)** values because they are **truly** predicted as class `2` values.\n",
        "\n",
        "||Predicted Class `1` (`y_predicted`)|Predicted Class `2` (`y_predicted`)|\n",
        "|-|-|-|\n",
        "|Actual Class `1` (`y_test`)|565 (TN)||\n",
        "|Actual Class `2` (`y_test`)|5 (FN)|0 (TP)|\n",
        "\n",
        "\n",
        "- `0` values are **False Positive (FP)** values because they are **falsely** predicted as class `2` values. They should have been predicted as class `1` values.\n",
        "\n",
        "||Predicted Class `1` (`y_predicted`)|Predicted Class `2` (`y_predicted`)|\n",
        "|-|-|-|\n",
        "|Actual Class `1` (`y_test`)|565 (TN)|0 (FP)|\n",
        "|Actual Class `2` (`y_test`)|5 (FN)|0 (TP)|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7bEEd-3mik_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRE1NWQxmjlV"
      },
      "source": [
        "#### Activity 2: Precision And Recall^\n",
        "\n",
        "A good prediction model provides a very large number of true positive (TP) values and a very low number of true negative (TN) values.\n",
        "\n",
        "**Precision:**\n",
        "\n",
        "Based on the TP and FP values, we define a parameter called **precision**. \n",
        "It is used to evaluate the number of correct positive predictions made.\n",
        "\n",
        "It is the ratio of the TP values to the sum of TP and FP values, i.e.,\n",
        "\n",
        "(defn of precision and recall)\n",
        "(precision of both outcomes.)\n",
        "(add example values)\n",
        "\n",
        "$$\\text{precision} = \\frac{\\text{TP}}{\\text{TP + FP}}$$\n",
        "\n",
        "Let us calculate the precision for exam software:\n",
        "\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/whj-negative-positive-apt-c17-01.png\" height=300/>\n",
        "\n",
        "For the above matrix,\n",
        "$$\\text{precision} = \\frac{\\text{TP}}{\\text{TP + FP}}=\\frac{\\text{65}}{\\text{65 + 5}}=\\text{0.928}$$\n",
        "\n",
        "Ideally, the precision should be 1 for a good classifier model. In this case, it is 0.928 which is quite good.\n",
        "\n",
        "Similarly, let's calculate the precision for our Random Forest classifier model.\n",
        "Currently, the model has given `0` TP values and `0` FP values. Therefore, the precision value is undefined because\n",
        "\n",
        "$$\\text{precision} = \\frac{0}{0 + 0} = \\text{undefined}$$\n",
        "\n",
        "*In mathematics, the division by 0 is undefined (or not defined).*\n",
        "\n",
        "**Recall:**\n",
        "\n",
        "Based on the TP and FN values, we define another parameter called **recall**.\n",
        "It is the ratio of the TP values to the sum of TP and FN values, i.e, \n",
        "\n",
        "$$\\text{recall} = \\frac{\\text{TP}}{\\text{TP + FN}}$$\n",
        "\n",
        "Let us calculate the precision for the exam software model:\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/whj-negative-positive-apt-c17-01.png\" height=300/>\n",
        "\n",
        "For the above matrix,\n",
        "$$\\text{recall} = \\frac{\\text{TP}}{\\text{TP + FN}}=\\frac{\\text{65}}{\\text{65 + 10}}=\\text{0.867}$$\n",
        "\n",
        "Ideally, the recall should be 1 for a good classifier model. In this case, it is 0.867 which is pretty good.\n",
        "\n",
        "Similarly, let's calculate the recall for our Random Forest classifier model.\n",
        "\n",
        "Currently, the model gives `0` TP and `5` FN values. Hence, the recall value is 0 because\n",
        "\n",
        "$$\\text{recall} = \\frac{0}{0+5} = \\text{0}$$\n",
        "\n",
        "Imagine if the prediction model labels every star as `2`, i.e, every star has a planet. Then, the number of TP values will be the maximum, i.e., `5` but the number of FP values will also be maximum, i.e., `565`. In such a case, the precision value would be\n",
        "\n",
        "$$\\text{precision} = \\frac{5}{5+565} = \\frac{5}{570} = 0.008$$\n",
        "\n",
        "which is very very low.\n",
        "\n",
        "Also, the model will give `0` FN values. Then, the recall value would be\n",
        "\n",
        "$$\\text{recall} = \\frac{5}{5 + 0} = 1$$\n",
        "\n",
        "\n",
        "So, even though the recall value would be equal to 1, the precision value would be close to 0. Hence, this would be a bad prediction model.\n",
        "\n",
        "\n",
        "Evidently, there is a trade-off. If the recall value is high, then the precision value will be low and vice-versa. Hence, we need to find an optimum point where both, the precision and the recall values are acceptable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHwSBiyi6Uud"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJQ8pWo76WQC"
      },
      "source": [
        "#### Activity 3: The `f1-score`\n",
        "\n",
        "To find an optimum point where both, the precision and recall values, are high, we calculate another parameter called **f1-score**. It is a harmonic mean of the precision and recall values, i.e.,\n",
        "\n",
        "\n",
        "\n",
        "$$\\text{f1-score} = 2 \\left( \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}} \\right)$$\n",
        "\n",
        "Let us calculate the f1-score for the exam software model:\n",
        "<img src=\"https://curriculum.whitehatjr.com/APT+Asset/APT+C17/whj-negative-positive-apt-c17-01.png\" height=300/>\n",
        "\n",
        "For the above matrix,\n",
        "$$\\text{f1-score} = 2 \\left( \\frac{\\text{0.928} \\times \\text{0.867}}{\\text{0.928} + \\text{0.867}} \\right)=\\text{0.896}$$\n",
        "\n",
        "f1-score will be high only when both precision and recall are high. In this case, it is 0.896 which is a good f1-score.\n",
        "\n",
        "Similarly, let's calculate the f1-score for our Random Forest classifier model.\n",
        "\n",
        "Based on the current predictions, the f1-scores value is undefined because both the precision and recall values are also undefined.\n",
        "\n",
        "$$\\text{f1-score} = 2 \\left( \\frac{\\text{undefined} \\times 0}{\\text{undefined} + 0} \\right) =  \\text{undefined}$$\n",
        "\n",
        "You can also get these values by calling a function called `classification_report()`. It takes two inputs: the actual target values and the predicted target values, i.e., `y_test` and `y_predicted`.\n",
        "\n",
        "**Note:** You may get the following warning message after executing the code in the code cell below.\n",
        "\n",
        "```\n",
        "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "```\n",
        "\n",
        "Ignore the warning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfyTwok0qHBv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0caaf55d-8ce7-44d8-eca5-981f2aab20e2"
      },
      "source": [
        "# Student Action: Print the 'precision', 'recall' and 'f1-score' values using the 'classification_report()' function.\n",
        "print(classification_report(y_test, y_predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      0.99      0.99       565\n",
            "           2       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.98       570\n",
            "   macro avg       0.50      0.50      0.50       570\n",
            "weighted avg       0.98      0.98      0.98       570\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4un_scgINE7f"
      },
      "source": [
        "As you can see, the `precision` and `f1-score` values are reported as `0.00` for class `2` because they are actually undefined values. \n",
        "  \n",
        "Ideally, the above values for class `2` should also be close to `1.00`. Then only we can say that our prediction model is satisfactory. This shows that accuracy alone cannot tell whether a prediction model is making correct predictions or not.\n",
        "\n",
        "In the next class, we will try to improve the model so that we get the desired precision, recall and f1-score values for class `2`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izmIyiq8QBhx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STZxEzUABIX2"
      },
      "source": [
        "### Additional Activities\n",
        "\n",
        "The activities starting from this point are optional. Please do these activities **ONLY** if you have time to spare in the class. Otherwise, skip to the **Wrap-Up** section. The additional activities will not be available in the class copy of the notebook. You will have to manually add these activities in the class copy by adding new text and code cells.\n",
        "\n",
        "Moreover, you don't have to do all the additional activities. Depending on the availability of time in a class, you can choose the number of additional activities to perform from this collection. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPkaT0k8BJcI"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iidnv7WCBKNN"
      },
      "source": [
        "#### Activity 1: Google Coding Challenge\n",
        "\n",
        "This coding question is taken from Google Coding Challenge\n",
        "\n",
        "**Problem**\n",
        "\n",
        "There are $N$ houses for sale. The $i^{\\text{th}}$ house costs $A_i$ dollars to buy. You have a budget of $B$ dollars to spend. What is the maximum number of houses you can buy?\n",
        "\n",
        "**Input**\n",
        "\n",
        "The first line of the input gives the number of test cases, $T$. $T$ test cases follow. Each test case begins with a single line containing the two integers $N$ and $B$. The second line contains $N$ integers. The $i^{\\text{th}}$ integer is $A_i$, the cost of the $i^{\\text{th}}$ house.\n",
        "\n",
        "**Output**\n",
        "\n",
        "For each test case, output one line containing `Case #x: y`, where `x` is the test case number (starting from 1) and `y` is the maximum number of houses you can buy.\n",
        "\n",
        "**Limits**\n",
        "\n",
        "$1 ≤ T ≤ 100$$\n",
        "\n",
        "$1 ≤ B ≤ 10^5$\n",
        "\n",
        "$1 ≤ A_i ≤ 1000$, for all $i$.\n",
        "\n",
        "\n",
        "**Sample** \n",
        "\n",
        "**Input** \n",
        "\n",
        "```\n",
        "3\n",
        "4 100\n",
        "20 90 40 90\n",
        "4 50\n",
        "30 30 10 10\n",
        "3 300\n",
        "999 999 999\n",
        "```\n",
        "\n",
        "**Output**\n",
        "\n",
        "```\n",
        "Case # 1 : 2\n",
        "Case # 2 : 3\n",
        "Case # 3 : 0\n",
        "```\n",
        "\n",
        "In Sample `Case #1`, you have a budget of `100` dollars. You can buy the first and third houses for `20 + 40 = 60` dollars.\n",
        "\n",
        "In Sample `Case #2`, you have a budget of `50` dollars. You can buy the first, third and fourth houses for `30 + 10 + 10 = 50` dollars.\n",
        "\n",
        "In Sample `Case #3`, you have a budget of `300` dollars. You cannot buy any houses. So the answer is `0`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq6mTVxu_Mqf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c1c986f0-0d41-40a1-becd-d9bea91abfee"
      },
      "source": [
        "# Solution:\n",
        "def max_affordable_houses(my_budget, house_prices):\n",
        "\tsum_house_prices = 0\n",
        "\tcount = 0\n",
        "\thouse_prices.sort()\n",
        "\tfor price in house_prices:\n",
        "\t\tsum_house_prices += int(price)\n",
        "\t\tif sum_house_prices > my_budget:\n",
        "\t\t\tcontinue\n",
        "\t\telse:\n",
        "\t\t\tcount += 1\n",
        "\treturn count\n",
        "\n",
        "test_cases = [] # This line of code should be shown to the students.\n",
        "num_test_cases = int(input()) # This line of code should be shown to the students.\n",
        "while num_test_cases > 0: # This line of code should be shown to the students.\n",
        "\tinput_list = input().split(' ') # This line of code should be shown to the students.\n",
        "\tnum_houses = int(input_list[0]) # This line of code should be shown to the students.\n",
        "\tmy_budget = int(input_list[1]) # This line of code should be shown to the students.\n",
        "\thouse_prices = input().split(' ') # This line of code should be shown to the students.\n",
        "\thouse_prices = [int(price) for price in house_prices] # This line of code should be shown to the students.\n",
        "\ttest_cases.append([my_budget, house_prices]) # This line of code should be shown to the students.\n",
        "\tnum_test_cases -= 1 # This line of code should be shown to the students.\n",
        "\n",
        "for i in range(len(test_cases)):\n",
        "\tmy_budget = test_cases[i][0]\n",
        "\thouse_prices = test_cases[i][1]\n",
        "\tprint(\"Case #\", i + 1, \":\", max_affordable_houses(my_budget, house_prices))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "4 100\n",
            "20 90 40 90\n",
            "4 50\n",
            "30 30 10 10\n",
            "3 100\n",
            "999 999 999\n",
            "Case # 1 : 2\n",
            "Case # 2 : 3\n",
            "Case # 3 : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7KPTy5KDV03"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t8lM7NyAksd"
      },
      "source": [
        "### Wrap-Up\n",
        "\n",
        "```\n",
        "TEACHER\n",
        "  Did you enjoy the class?\n",
        "\n",
        "EXPECTED STUDENT RESPONSE\n",
        "  Yes, teacher.\n",
        "\n",
        "\n",
        "TEACHER\n",
        "  What part of the class did you enjoy?\n",
        "\n",
        "EXPECTED STUDENT RESPONSE\n",
        "  I enjoyed everything.\n",
        "\n",
        "\n",
        "TEACHER\n",
        "  I am glad you are having a good time. But make sure that you practice \n",
        "  writing code in your free time.\n",
        "\n",
        "EXPECTED STUDENT RESPONSE\n",
        "  Sure teacher.\n",
        "\n",
        "\n",
        "TEACHER\n",
        "  Congratulations! You've reached a milestone. You can now attempt Project \n",
        "  Gender Voices Classification. In this project, you will be provided with a \n",
        "  dataset which contains some statistical information about the audio \n",
        "  frequencies of different male and female voices. Based on the information \n",
        "  provided, you have to find out which voice belongs to which gender using the \n",
        "  Random Forest Classifier algorithm.\n",
        "  \n",
        "  In the next class, we will learn how to process the training dataset so \n",
        "  that our prediction model makes accurate predictions. This step is \n",
        "  called data processing. It enables a prediction model (or algorithm) \n",
        "  to learn the properties of data in an effective manner so that it can \n",
        "  distinguish between different types of data in a dataset.\n",
        "  \n",
        "EXPECTED STUDENT RESPONSE\n",
        "  Sure teacher.\n",
        "\n",
        "\n",
        "TEACHER\n",
        "  See you in the next class. Bye!\n",
        "\n",
        "EXPECTED STUDENT RESPONSE\n",
        "  Bye teacher!\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kfXvaUPAl8a"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXB0b6l8AqY8"
      },
      "source": [
        "### Activities\n",
        "\n",
        "**Teacher Activities**\n",
        "\n",
        "1. Hunting Exoplanets In Space - Model Evaluation (Class Copy)\n",
        "\n",
        "   https://colab.research.google.com/drive/1dsrP-6aEDKa05xhfq6ewWYG2bQtfBS1j\n",
        "\n",
        "2. Hunting Exoplanets In Space - Model Evaluation (Reference)\n",
        "\n",
        "   https://colab.research.google.com/drive/1H1SDf0Iuqf-BkZXSs9YXXyJvlnssMFRG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTcaxRROAo9m"
      },
      "source": [
        "---"
      ]
    }
  ]
}